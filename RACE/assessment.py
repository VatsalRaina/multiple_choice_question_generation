import argparse
import os
import sys

import torch
from torch.utils.data import TensorDataset, DataLoader
import numpy as np
from numpy.lib.arraysetops import unique

from transformers import ElectraTokenizer, ElectraForMultipleChoice, ElectraConfig
from keras.preprocessing.sequence import pad_sequences

MAXLEN = 512

parser = argparse.ArgumentParser(description='Get all command line arguments.')
parser.add_argument('--questions_path', type=str,  help='Specify path to generated questions')
parser.add_argument('--contexts_path', type=str,  help='Specify path to contexts')
parser.add_argument('--models_dir', type=str, help='Specify path to directory containing all trained models')

def get_default_device():
    if torch.cuda.is_available():
        print("Got CUDA!")
        return torch.device('cuda')
    else:
        return torch.device('cpu')

def organise_data(questions, contexts):
    organised_data = []
    for question, context in zip(questions, contexts):
        first_sep_pos = question.find("[SEP]")
        qu = question[:first_sep_pos]
        opts = []
        validSEP = True
        sep_pos = first_sep_pos
        while validSEP:
            question = question[sep_pos+6:]
            sep_pos = question.find("[SEP]")
            if sep_pos == -1:
                validSEP = False
                opt = question
            else:
                opt = question[:sep_pos]
            opts.append(opt)
        curr_point = {'question': qu, 'context': context, 'options':opts, 'label':0}
        # print(curr_point)
        organised_data.append(curr_point)
    return organised_data

def got_four_opts(test_data):
    num_valid = 0
    for ex in test_data:
        unique_opts = []
        for opt in ex['options']:
            if opt not in unique_opts:
                unique_opts.append(opt)
        if len(unique_opts) == 4:
            num_valid += 1
    return num_valid / len(test_data)

def clean(test_data):
    """"
    Each example must have 4 answer options. So if fewer than four answer
    options are provided then the additional options are generated by 
    duplicating the final provided answer option.
    """
    clean_data = []
    for ex in test_data:
        question, context, options = test_data['question'], test_data['context'], test_data['options']
        if len(options) !=4:
            last_option = options[-1]
            while len(options) < 4:
                options.append(last_option)
        curr_point = {'question': question, 'context': context, 'options':options, 'label':0}
        clean_data.append(curr_point)
    return clean_data
        


def get_qa_predictions(test_data, models, device):

    repeated_data = clean(test_data)
    test_data = repeated_data

    electra_large = "google/electra-large-discriminator"
    tokenizer = ElectraTokenizer.from_pretrained(electra_large, do_lower_case=True)

    input_ids = []
    token_type_ids = []
    count = 0
    for ex in test_data:
        question, context, options = test_data['question'], test_data['context'], test_data['options']
        four_inp_ids = []
        four_tok_type_ids = []
        for opt in options:
            combo = context + " [SEP] " + question + " " + opt
            inp_ids = tokenizer.encode(combo)
            if len(inp_ids)>512:
                inp_ids = inp_ids[-512:]
            tok_type_ids = [0 if i<= inp_ids.index(102) else 1 for i in range(len(inp_ids))]
            four_inp_ids.append(inp_ids)
            four_tok_type_ids.append(tok_type_ids)
        four_inp_ids = pad_sequences(four_inp_ids, maxlen=MAXLEN, dtype="long", value=0, truncating="post", padding="post")
        four_tok_type_ids = pad_sequences(four_tok_type_ids, maxlen=MAXLEN, dtype="long", value=0, truncating="post", padding="post")
        input_ids.append(four_inp_ids)
        token_type_ids.append(four_tok_type_ids)

    # Create attention masks
    attention_masks = []
    for sen in input_ids:
        sen_attention_masks = []
        for opt in sen:
            att_mask = [int(token_id > 0) for token_id in opt]
            sen_attention_masks.append(att_mask)
        attention_masks.append(sen_attention_masks)
    # Convert to torch tensors
    input_ids = torch.tensor(input_ids)
    input_ids = input_ids.long().to(device)
    token_type_ids = torch.tensor(token_type_ids)
    token_type_ids = token_type_ids.long().to(device)
    attention_masks = torch.tensor(attention_masks)
    attention_masks = attention_masks.long().to(device)

    ds = TensorDataset(input_ids, token_type_ids, attention_masks)
    dl = DataLoader(ds, batch_size=args.batch_size, shuffle=False)

    logits_all_models = []
    for i, model in enumerate(models):
        print("Model:", i)
        logits = []
        count = 0
        for inp_id, tok_typ_id, att_msk in dl:
            print(count)
            count+=1
            inp_id, tok_typ_id, att_msk = inp_id.to(device), tok_typ_id.to(device), att_msk.to(device)
            with torch.no_grad():
                outputs = model(input_ids=inp_id, attention_mask=att_msk, token_type_ids=tok_typ_id)
            curr_logits = outputs[0]
            logits += curr_logits.detach().cpu().numpy().tolist()
        logits_all_models.append(logits)
    logits_all_models = np.asarray(logits_all_models)
    return logits_all_models



def get_unanswerability(all_logits):
    pass

def get_accuracy(all_logits):
    ens_logits = np.mean(all_logits, axis=0)
    class_preds = np.argmax(ens_logits, axis=-1)
    num_correct = 0
    for pred in class_preds:
        if pred == 0:
            num_correct += 1

    return num_correct / len(class_preds)


def get_complexity():
    pass

def main(args):
    if not os.path.isdir('CMDs'):
        os.mkdir('CMDs')
    with open('CMDs/train.cmd', 'a') as f:
        f.write(' '.join(sys.argv) + '\n')
        f.write('--------------------------------\n')

    with open(args.questions_path, 'r') as f:
        all_gen_questions = [a.rstrip() for a in f.readlines()]

    with open(args.contexts_path, 'r') as f:
        all_contexts = [a.rstrip() for a in f.readlines()]

    organised_data = organise_data(all_gen_questions, all_contexts)

    frac_four_opts = got_four_opts(organised_data)
    print("Fraction of samples with 4 unique options:", frac_four_opts)


    device = get_default_device()
    models = []
    seeds = [1, 2, 3, 4, 5, 6, 17, 8, 9, 10]
    for seed in seeds:
        model_path = args.models_dir + str(seed) + '/electra_QA_MC_seed' + str(seed) + '.pt'
        model = torch.load(model_path, map_location=device)
        model.eval().to(device)
        models.append(model)
    
    all_logits = get_qa_predictions(organised_data, models, device)

    # frac_unans = get_unanswerability(all_logits)

    frac_acc = get_accuracy(all_logits)
    print("Fraction accuracy:", frac_acc)

if __name__ == '__main__':
    args = parser.parse_args()
    main(args)